groups:
- name: prometheus-metamon.rules
  rules:
  - alert: PrometheusUnreachable
    expr: up{job=~"prometheus.*", fqdn !~ ".*gprd.*"} == 0
    for: 10m
    labels:
      pager: pagerduty
      service: prometheus
      severity: critical
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} could not be scraped for
        over 10 minutes.'
      runbook: troubleshooting/prometheus-is-down.md
      title: '{{$labels.job}} is unreachable'
  - alert: PrometheusManyRestarts
    expr: changes(process_start_time_seconds{job=~"prometheus.*", fqdn !~ ".*gprd.*"}[30m]) > 3
    for: 30m
    labels:
      pager: pagerduty
      service: prometheus
      severity: critical
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has restarted more than
        3 times in the last 30 minutes. It might be crashlooping.'
      runbook: troubleshooting/prometheus-is-down.md
      title: '{{$labels.job}} is restarting frequently'
  - alert: PrometheusManyFileSDReadErrors
    expr: rate(prometheus_sd_file_read_errors_total{job=~"prometheus.*"}[5m]) / rate(prometheus_sd_file_scan_duration_seconds_count{job=~"prometheus.*"}[5m])
      * 100 > 5
    for: 10m
    labels:
      service: prometheus
      severity: warn
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has {{$value}}% of DNS-SD
        requests failing.'
      runbook: troubleshooting/prometheus-file-sd-errors.md
      title: '{{$labels.job}} has many DNS-SD errors'
  - alert: PrometheusRuleEvaluationSlow
    expr: prometheus_evaluator_duration_seconds{job=~"prometheus.*",quantile="0.9"}
      > 60
    for: 10m
    labels:
      service: prometheus
      severity: warn
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has a 90th percentile
        latency of {{$value}}s completing rule evaluation cycles.'
      runbook: troubleshooting/prometheus-slow-rule-eval.md
      title: '{{$labels.job}} is evaluating rules too slowly'
  - alert: PrometheusNotificationsBacklog
    expr: prometheus_notifications_queue_length{job=~"prometheus.*", fqdn !~ ".*gprd.*"} > 0
    for: 10m
    labels:
      pager: pagerduty
      service: prometheus
      severity: critical
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} is backlogging on the
        notifications queue. The queue has not been empty for 10 minutes. Current
        queue length: {{$value}}.'
      runbook: troubleshooting/prometheus-notifications-backlog.md
      title: '{{$labels.job}} is backlogging on the notifications queue'
  - alert: PrometheusScrapingSlowly
    expr: prometheus_target_interval_length_seconds{interval!~".*m.*",job=~"prometheus.*",quantile="0.9"}
      > 2 * 60
    for: 10m
    labels:
      service: prometheus
      severity: warn
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has a 90th percentile
        latency of {{$value}}s for scraping targets in the {{$labels.interval}} target
        pool.'
      runbook: troubleshooting/prometheus-slow-scrapes.md
      title: '{{$labels.job}} is scraping targets slowly'
  - alert: PrometheusInvalidConfigFile
    expr: prometheus_config_last_reload_successful{job=~"prometheus.*", fqdn !~ ".*gprd.*"} == 0
    for: 30m
    labels:
      pager: pagerduty
      service: prometheus
      severity: critical
    annotations:
      description: The configuration file for {{$labels.job}} at {{$labels.instance}}
        is invalid and was therefore not reloaded.
      runbook: troubleshooting/prometheus-invalid-config.md
      title: '{{$labels.job}} has an invalid config'
  - alert: PrometheusOutOfOrderSamples
    expr: increase(prometheus_target_scrapes_sample_out_of_order_total[10m])
      > 0
    for: 1h
    labels:
      service: prometheus
      severity: warn
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has discarded {{$value}}
        out-of-order samples over the last hour.'
      runbook: troubleshooting/prometheus-out-of-order.md
      title: '{{$labels.job}} is discarding out-of-order samples'
  - alert: PrometheusWalCorruptions
    expr: increase(tsdb_wal_corruptions_total[1h]) > 0
    labels:
      service: prometheus
      severity: warn
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has {{$value}} wal corruptions'
      runbook: troubleshooting/prometheus-wal-corruptions.md
      title: '{{$labels.job}} wal corruptions'
  - alert: PrometheusComapctionFailures
    expr: increase(prometheus_tsdb_compactions_failed_total[1h]) > 0
    labels:
      service: prometheus
      severity: warn
    annotations:
      description: '{{$labels.job}} at {{$labels.instance}} has {{$value}} failed compactions'
      runbook: troubleshooting/prometheus-wal-corruptions.md
      title: '{{$labels.job}} failed compactions'
